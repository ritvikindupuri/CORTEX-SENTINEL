# CORTEX SENTINEL // ENGINEERING WHITEPAPER

**System:** Cortex Sentinel V2.1 (Hybrid Architecture)
**Author:** Ritvik Indupuri
**Date:** November 14, 2025
**Classification:** TECHNICAL REFERENCE

---

## 1.0 EXECUTIVE SUMMARY

Cortex Sentinel is a **Hybrid Defense Grid** designed to detect, classify, and neutralize "Agentic Breakouts" (autonomous AI operations). It addresses the security gap where traditional regex-based firewalls fail to detect semantic threats generated by Large Language Models (LLMs).

The system leverages a **Bicameral Architecture**:
1.  **The Adversary (Attacker):** Acts as the "Red Team". It uses Google Gemini (Cloud) or scripts to *write* the attack story.
2.  **The Sentinel (Defender):** Acts as the "Blue Team". It uses TensorFlow.js (Local) to *read* the story and use math to decide if it represents a threat.

---

## 2.0 SYSTEM ARCHITECTURE

The application follows a unidirectional data flow pattern, ensuring state consistency between the simulation engine and the visualization layer.

### 2.1 Architecture Diagram

```text
[ USER ] interacts with UI
   |
   v
[ THREAT HUNTER COMPONENT ]
   |
   +--- (A) GENERATION PATHWAY (The Attacker) -----------+
   |    1. User Click "Generate Log"                     |
   |    2. Check for API Key                             |
   |       |-- YES: Call Gemini 2.5 Flash (The Brain)    |
   |       |-- NO:  Call Procedural Script (Fallback)    |
   |    3. Output: Realistic JSON Log Entry              |
   +-----------------------------------------------------+
   |
   v
[ INPUT BUFFER (Terminal UI) ]
   |
   +--- (B) ANALYSIS PATHWAY (The Defender) -------------+
   |    1. User Clicks "Analyze Telemetry"               |
   |    2. Input String -> NeuralService                 |
   |    3. TENSORFLOW.JS (WebGL Backend)                 |
   |       |-- Input -> Universal Sentence Encoder       |
   |       |-- Output -> 512-Dim Vector Embedding        |
   |       |-- Math -> Dot Product vs. Threat Anchors    |
   |    4. Heuristic Checks (Regex/Pattern)              |
   |    5. Output: ThreatAnalysis Object                 |
   +-----------------------------------------------------+
   |
   v
[ APP STATE (React Context) ]
   |
   +--- Updates OPS CENTER (Dashboard Metrics)
   +--- Appends to RAW TELEMETRY (Audit Log)
   +--- Serialized to SESSION STORAGE (History)
```

---

## 3.0 COMPONENT DEEP DIVE: THE ATTACKER (GENERATOR)

This component acts as the **"Red Team"** or adversary. Its sole job is to create the data.

### 3.1 How It Works
When the user clicks **"Generate Log"**, the app calls the `generateSimulation` function in `services/gemini.ts`.

### 3.2 The Brain (Dual-Mode Engine)
The Generator has two modes of operation:

1.  **Cloud Mode (Google Gemini 2.5 Flash):**
    *   **Trigger:** Active API Key.
    *   **Behavior:** The app sends a prompt to Gemini asking it to *pretend* to be a hacker tool (like Nmap, SQLMap, or an Agentic AI).
    *   **Result:** Highly varied, context-aware, and realistic attack logs. It "hallucinates" the attack based on the prompt constraints.

2.  **Local Mode (Procedural Script):**
    *   **Trigger:** No API Key or Offline.
    *   **Behavior:** Uses a JavaScript function that acts like a "Mad Libs" engine. It creates logs using pre-defined templates, filling in the blanks with randomized IP addresses, timestamps, and user agents.
    *   **Result:** Deterministic, reliable logs that ensure the app functions perfectly without an internet connection.

### 3.3 Realism & Tradecraft Modeling
To ensure the "Solution" is valid, we model real-world Attacker Tradecraft.
*   **RedScan Protocol:** The prompt specifically instructs the AI to mimic the "RedScan" agentic behavior defined in the security report: low-latency requests, JSON headers with missing signatures, and "authorized audit" social engineering attempts.
*   **Tool Emulation:** The system does not run binaries (like Nmap) but *emulates* their output text, allowing for safe, sandbox-free testing of detection logic.

### 3.4 Attack Vector Prompt Strategies (Cloud Mode)
How Gemini is "trained" via prompt engineering for each unique vector:
*   **Reconnaissance:** Prompted to simulate `nmap` style JSON outputs, specifically focusing on port scanning behavior.
*   **Exploitation:** Prompted to simulate high-velocity API calls (`latency < 10ms`) to trigger the Velocity Guardrail.
*   **Exfiltration:** Prompted to generate large Base64 payloads to simulate Context Window Overflow attempts.
*   **Social Engineering:** Prompted to generate conversational logs where a user requests "authorized access" to test semantic analysis.

### 3.5 Procedural Template Logic (Local Mode)
When offline, the engine uses a `switch` statement to mathematically construct logs based on the selected vector:
*   **Dynamic Injection:** Calculates random IPs (`192.168.x.x`) and current ISO timestamps to ensure uniqueness.
*   **Reconnaissance Template:** Injects a hardcoded `PORT_SCAN_DETECTED` event with random port arrays `[22, 80, 443]`.
*   **Exploitation Template:** Specifically constructs a `TOOL_EXECUTION_SPIKE` event with `latency: "4ms"`. This is designed to mathematically trigger the Defender's Velocity Heuristic.
*   **RedScan Protocol Template:** Injects `auth_signature: null` to guarantee a Protocol Guardrail trigger.
*   **Exfiltration Template:** Injects `status: "TRUNCATED"` and `method: "BASE64_CHUNKED"` to simulate context window overflow.

---

## 4.0 COMPONENT DEEP DIVE: THE DEFENDER (ANALYZER)

This component acts as the **"Blue Team"** or security system. Its job is to detect threats in the data generated by the Attacker.

### 4.1 How It Works
When the user clicks **"Analyze Telemetry"**, the app calls the `analyzeThreatLog` function. This runs entirely client-side in the browser.

### 4.2 The Brain (TensorFlow.js)
The Defender uses the **Universal Sentence Encoder (USE)** running on WebGL via TensorFlow.js.

### 4.3 The Process
1.  **Input:** It takes the text log string (either generated by the Attacker OR pasted manually by the user).
2.  **Vectorization:** It feeds the text into the Neural Network, which converts the semantic meaning into a **512-dimensional vector** (a list of 512 numbers).
3.  **Comparison:** It compares this vector against **"Threat Anchors"**â€”definitions of bad behavior (like "malware", "injection", "overflow") that we taught the model at startup.
4.  **Math:** It calculates the **Cosine Similarity** (Vector Dot Product) between the Input Vector and the Threat Anchor.
    *   `Score > 0.6` = Semantic Match (Threat).
5.  **Guardrails:** It simultaneously runs regex checks for